{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 22:51:25.093998: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-19 22:51:25.144166: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-19 22:51:25.144194: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-19 22:51:25.145311: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-19 22:51:25.153531: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-19 22:51:28.624272: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mia.models import ShadowModelBundle, AttackModelBundle, prepare_attack_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "WIDTH = 32\n",
    "HEIGHT = 32\n",
    "CHANNELS = 3\n",
    "SHADOW_DATASET_SIZE = 4000\n",
    "ATTACK_TEST_DATASET_SIZE = 4000\n",
    "\n",
    "TARGET_EPOCHS = 12\n",
    "ATTACK_EPOCHS = 12\n",
    "NUM_SHADOWS = 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"Prepare CIFAR10 data.\"\"\"\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    y_train = tf.keras.utils.to_categorical(y_train)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test)\n",
    "    X_train = X_train.astype(\"float32\")\n",
    "    X_test = X_test.astype(\"float32\")\n",
    "    y_train = y_train.astype(\"float32\")\n",
    "    y_test = y_test.astype(\"float32\")\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def target_model_fn():\n",
    "    \"\"\"The architecture of the target (victim) model.\n",
    "\n",
    "    The attack is white-box, hence the attacker is assumed to know this architecture too.\"\"\"\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2D(\n",
    "            32,\n",
    "            (3, 3),\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\",\n",
    "            input_shape=(WIDTH, HEIGHT, CHANNELS),\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    model.compile(\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def attack_model_fn():\n",
    "    \"\"\"Attack model that takes target model predictions and predicts membership.\n",
    "\n",
    "    Following the original paper, this attack model is specific to the class of the input.\n",
    "    AttachModelBundle creates multiple instances of this model for each class.\n",
    "    \"\"\"\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(layers.Dense(128, activation=\"relu\", input_shape=(NUM_CLASSES,)))\n",
    "\n",
    "    model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the target model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 22:51:35.310498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22987 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:41:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 22:51:37.599012: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-11-19 22:51:37.767713: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2023-11-19 22:51:38.057047: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-11-19 22:51:38.147387: W external/local_xla/xla/stream_executor/gpu/redzone_allocator.cc:322] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-11-19 22:51:38.452686: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:504] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-12.2\n",
      "  /usr/local/cuda\n",
      "  /users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2023-11-19 22:51:38.640953: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-11-19 22:51:38.735942: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-19 22:51:38.833064: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-11-19 22:51:38.925241: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-19 22:51:39.025260: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-11-19 22:51:39.118555: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-19 22:51:39.215667: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-11-19 22:51:39.310893: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-19 22:51:39.409790: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-11-19 22:51:39.501665: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-19 22:51:39.602825: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-11-19 22:51:39.695784: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-19 22:51:39.795033: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-11-19 22:51:39.890126: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-19 22:51:39.991268: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-11-19 22:51:40.083327: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-19 22:51:40.186777: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-11-19 22:51:40.280289: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-19 22:51:40.851264: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-11-19 22:51:40.944712: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-11-19 22:51:41.020840: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f124dc6cd60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-19 22:51:41.020863: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 6000, Compute Capability 7.5\n",
      "2023-11-19 22:51:41.027142: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-19 22:51:41.052434: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.053453: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.075563: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.076512: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.102866: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.104115: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.126104: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.127031: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.261123: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.262129: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.286347: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.287312: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : INTERNAL: libdevice not found at ./libdevice.10.bc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 22:51:41.350381: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.351580: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.373403: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.374389: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.440073: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.441075: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.465371: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.466343: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.509459: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.510469: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.532309: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-11-19 22:51:41.533244: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:574 : INTERNAL: libdevice not found at ./libdevice.10.bc\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node Adam/StatefulPartitionedCall_10 defined at (most recent call last):\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 737, in start\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3046, in run_cell\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3101, in _run_cell\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3488, in run_ast_nodes\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n\n  File \"/tmp/ipykernel_135258/1763383792.py\", line 6, in <module>\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1154, in train_step\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1253, in _internal_apply_gradients\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1340, in apply_grad_to_update_var\n\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node Adam/StatefulPartitionedCall_10}}]] [Op:__inference_train_function_1687]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the target model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m target_model \u001b[38;5;241m=\u001b[39m target_model_fn()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtarget_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTARGET_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train the shadow models.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m smb \u001b[38;5;241m=\u001b[39m ShadowModelBundle(\n\u001b[1;32m     12\u001b[0m     target_model_fn,\n\u001b[1;32m     13\u001b[0m     shadow_dataset_size\u001b[38;5;241m=\u001b[39mSHADOW_DATASET_SIZE,\n\u001b[1;32m     14\u001b[0m     num_models\u001b[38;5;241m=\u001b[39mNUM_SHADOWS,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m~/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node Adam/StatefulPartitionedCall_10 defined at (most recent call last):\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 737, in start\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3046, in run_cell\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3101, in _run_cell\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3488, in run_ast_nodes\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n\n  File \"/tmp/ipykernel_135258/1763383792.py\", line 6, in <module>\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1154, in train_step\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1253, in _internal_apply_gradients\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n\n  File \"/users/xli321/data/xli321/conda_envs/mia_env/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1340, in apply_grad_to_update_var\n\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node Adam/StatefulPartitionedCall_10}}]] [Op:__inference_train_function_1687]"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = get_data()\n",
    "\n",
    "# Train the target model.\n",
    "print(\"Training the target model...\")\n",
    "target_model = target_model_fn()\n",
    "target_model.fit(\n",
    "    X_train, y_train, epochs=TARGET_EPOCHS, validation_split=0.1, verbose=True\n",
    ")\n",
    "\n",
    "# Train the shadow models.\n",
    "smb = ShadowModelBundle(\n",
    "    target_model_fn,\n",
    "    shadow_dataset_size=SHADOW_DATASET_SIZE,\n",
    "    num_models=NUM_SHADOWS,\n",
    ")\n",
    "\n",
    "# We assume that attacker's data were not seen in target's training.\n",
    "attacker_X_train, attacker_X_test, attacker_y_train, attacker_y_test = train_test_split(\n",
    "    X_test, y_test, test_size=0.1\n",
    ")\n",
    "print(attacker_X_train.shape, attacker_X_test.shape)\n",
    "\n",
    "print(\"Training the shadow models...\")\n",
    "X_shadow, y_shadow = smb.fit_transform(\n",
    "    attacker_X_train,\n",
    "    attacker_y_train,\n",
    "    fit_kwargs=dict(\n",
    "        epochs=FLAGS.target_epochs,\n",
    "        verbose=True,\n",
    "        validation_data=(attacker_X_test, attacker_y_test),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# ShadowModelBundle returns data in the format suitable for the AttackModelBundle.\n",
    "amb = AttackModelBundle(attack_model_fn, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Fit the attack models.\n",
    "print(\"Training the attack models...\")\n",
    "amb.fit(\n",
    "    X_shadow, y_shadow, fit_kwargs=dict(epochs=ATTACK_EPOCHS, verbose=True)\n",
    ")\n",
    "\n",
    "# Test the success of the attack.\n",
    "\n",
    "# Prepare examples that were in the training, and out of the training.\n",
    "data_in = X_train[:ATTACK_TEST_DATASET_SIZE], y_train[:ATTACK_TEST_DATASET_SIZE]\n",
    "data_out = X_test[:ATTACK_TEST_DATASET_SIZE], y_test[:ATTACK_TEST_DATASET_SIZE]\n",
    "\n",
    "# Compile them into the expected format for the AttackModelBundle.\n",
    "attack_test_data, real_membership_labels = prepare_attack_data(\n",
    "    target_model, data_in, data_out\n",
    ")\n",
    "\n",
    "# Compute the attack accuracy.\n",
    "attack_guesses = amb.predict(attack_test_data)\n",
    "attack_accuracy = np.mean(attack_guesses == real_membership_labels)\n",
    "\n",
    "print(attack_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mia_env)",
   "language": "python",
   "name": "mia_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
